{
  "grok": {
    "model": "xai/grok-3",
    "text": "I'll design a Next.js 15 app that compares three AI models using Vercel's AI Gateway while maintaining a $10 budget. The solution will include parallel model calls, a scoring system, cost tracking, and a results dashboard. I'll leverage Vercel's latest features including AI Gateway (Beta) and Active CPU billing.\n\n### Project Structure\n\n```\nai-model-comparator/\n├── app/\n│   ├── api/\n│   │   └── compare/route.ts     # API endpoint for model comparison\n│   └── page.tsx                 # Main UI with dashboard\n├── components/\n│   ├── Judge.tsx               # Scoring component for responses\n│   ├── Dashboard.tsx           # Results display with rankings and costs\n│   └── CostTracker.tsx         # Budget monitoring component\n├── lib/\n│   ├── ai-gateway.ts           # AI Gateway integration\n│   └── cost-tracker.ts         # Cost calculation and tracking\n├── public/                     # Static assets if needed\n├── middleware.ts               # Optional rate limiting for budget control\n├── next.config.js              # Next.js configuration\n└── package.json                # Dependencies\n```\n\n### Implementation Details\n\n#### 1. Setup and Dependencies\n\nFirst, set up a Next.js 15 project with TypeScript and install necessary dependencies for Vercel AI Gateway integration.\n\n```bash\nnpx create-next-app@latest ai-model-comparator --typescript --use-pnpm\npnpm add @vercel/ai-gateway\npnpm add recharts # For dashboard visualizations\n```\n\n#### 2. AI Gateway Integration (`lib/ai-gateway.ts`)\n\nConfigure Vercel's AI Gateway to call Grok, Claude, and Gemini in parallel. We'll use environment variables for API keys and budget limits.\n\n```typescript\n// lib/ai-gateway.ts\nimport { createAIClient } from '@vercel/ai-gateway';\n\nconst API_KEY_GROK = process.env.GROK_API_KEY || '';\nconst API_KEY_CLAUDE = process.env.CLAUDE_API_KEY || '';\nconst API_KEY_GEMINI = process.env.GEMINI_API_KEY || '';\n\nconst clients = {\n  grok: createAIClient({\n    provider: 'xai',\n    apiKey: API_KEY_GROK,\n    model: 'grok-1',\n  }),\n  claude: createAIClient({\n    provider: 'anthropic',\n    apiKey: API_KEY_CLAUDE,\n    model: 'claude-3-opus-20240229',\n  }),\n  gemini: createAIClient({\n    provider: 'google',\n    apiKey: API_KEY_GEMINI,\n    model: 'gemini-1.5-pro',\n  }),\n};\n\nexport async function compareModels(prompt: string) {\n  try {\n    // Call all models in parallel\n    const responses = await Promise.all([\n      clients.grok.chat.completions.create({\n        messages: [{ role: 'user', content: prompt }],\n        max_tokens: 300,\n      }),\n      clients.claude.chat.completions.create({\n        messages: [{ role: 'user', content: prompt }],\n        max_tokens: 300,\n      }),\n      clients.gemini.chat.completions.create({\n        messages: [{ role: 'user', content: prompt }],\n        max_tokens: 300,\n      }),\n    ]);\n\n    return {\n      grok: responses[0].choices[0].message.content,\n      claude: responses[1].choices[0].message.content,\n      gemini: responses[2].choices[0].message.content,\n      usage: responses.map(r => r.usage),\n    };\n  } catch (error) {\n    console.error('AI Gateway Error:', error);\n    throw new Error('Failed to fetch responses from AI models');\n  }\n}\n```",
    "promptTokens": 178,
    "completionTokens": 842,
    "cost": 0.0127
  },
  "claude": {
    "model": "anthropic/claude-4-opus",
    "text": "I'll help you design a Next.js 15 app with Vercel's AI Gateway to compare AI models. Here's a comprehensive implementation:\n\n## Project Structure\n\n```\nai-model-comparison/\n├── app/\n│   ├── api/\n│   │   ├── compare/route.ts\n│   │   └── judge/route.ts\n│   ├── components/\n│   │   ├── ModelComparison.tsx\n│   │   ├── ResultsDashboard.tsx\n│   │   ├── CostTracker.tsx\n│   │   └── JudgePanel.tsx\n│   ├── lib/\n│   │   ├── ai-gateway.ts\n│   │   ├── cost-calculator.ts\n│   │   └── types.ts\n│   ├── layout.tsx\n│   └── page.tsx\n├── package.json\n└── vercel.json\n```\n\n## 1. Setup and Dependencies\n\n```json\n// package.json\n{\n  \"name\": \"ai-model-comparison\",\n  \"version\": \"0.1.0\",\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\"\n  },\n  \"dependencies\": {\n    \"next\": \"15.0.0\",\n    \"react\": \"^18.3.0\",\n    \"react-dom\": \"^18.3.0\",\n    \"@vercel/ai\": \"^3.0.0\",\n    \"@vercel/kv\": \"^1.0.0\",\n    \"ai\": \"^3.0.0\",\n    \"openai\": \"^4.0.0\",\n    \"@anthropic-ai/sdk\": \"^0.20.0\",\n    \"@google/generative-ai\": \"^0.7.0\",\n    \"zod\": \"^3.22.0\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.0.0\",\n    \"@types/react\": \"^18.0.0\",\n    \"@types/react-dom\": \"^18.0.0\",\n    \"typescript\": \"^5.0.0\"\n  }\n}\n```\n\n## 2. Vercel Configuration\n\n```json\n// vercel.json\n{\n  \"functions\": {\n    \"app/api/compare/route.ts\": {\n      \"maxDuration\": 30\n    },\n    \"app/api/judge/route.ts\": {\n      \"maxDuration\": 20\n    }\n  },\n  \"env\": {\n    \"VERCEL_AI_GATEWAY_URL\": \"@vercel-ai-gateway-url\",\n    \"ANTHROPIC_API_KEY\": \"@anthropic-api-key\",\n    \"GOOGLE_AI_API_KEY\": \"@google-ai-api-key\",\n    \"GROK_API_KEY\": \"@grok-api-key\"\n  }\n}\n```\n\n## 3. Types Definition\n\n```typescript\n// app/lib/types.ts\nexport interface ModelResponse {\n  model: 'grok' | 'claude' | 'gemini';\n  response: string;\n  cost: number;\n  latency: number;\n  error?: string;\n}\n\nexport interface JudgeScore {\n  relevance: number;\n  reasoning: number;\n  style: number;\n  overall: number;\n  feedback: string;\n}\n\nexport interface ComparisonResult {\n  prompt: string;\n  responses: ModelResponse[];\n  scores: Record<string, JudgeScore>;\n  totalCost: number;\n  timestamp: Date;\n}\n\nexport interface CostTracking {\n  totalSpent: number;\n  budget: number;\n  remainingBudget: number;\n  costByModel: Record<string, number>;\n}\n```",
    "promptTokens": 178,
    "completionTokens": 785,
    "cost": 0.0648
  },
  "gemini": {
    "model": "google/gemini-2.5-pro",
    "text": "Of course. Here is a comprehensive design for a Next.js 15 application that uses Vercel's AI Gateway to compare Grok, Claude, and Gemini within a $10 budget. This design leverages modern Next.js features like Server Actions and Vercel's latest infrastructure.\n\n### Core Concepts & Technology Stack\n\n* **Framework:** Next.js 15 (using React Server Components & Server Actions)\n* **AI Orchestration:** Vercel AI Gateway (Beta) with @vercel/ai SDK\n* **Models:** Grok (xAI), Claude (Anthropic), Gemini (Google)\n* **Billing:** Active CPU + Fluid Compute (GA in 2025)\n* **Optional Features:** Sandbox (Public Beta), Queues (Limited Beta if available)\n* **UI:** Tailwind CSS + Radix UI\n* **Cost Tracking:** Server-side with Redis/KV storage\n\n### Application Architecture\n\n```\nai-model-comparator/\n├── app/\n│   ├── api/\n│   │   └── ai-gateway/\n│   │       └── route.ts          # AI Gateway proxy endpoint\n│   ├── actions/\n│   │   ├── compare-models.ts    # Server action for model comparison\n│   │   ├── judge-responses.ts   # Server action for scoring\n│   │   └── track-costs.ts       # Cost tracking logic\n│   ├── components/\n│   │   ├── model-input.tsx      # Prompt input component\n│   │   ├── model-cards.tsx      # Display model responses\n│   │   ├── judge-panel.tsx      # Scoring interface\n│   │   ├── cost-tracker.tsx     # Real-time cost display\n│   │   └── results-dashboard.tsx # Rankings & visualizations\n│   ├── lib/\n│   │   ├── ai-gateway.ts        # AI Gateway configuration\n│   │   ├── cost-calculator.ts   # Cost calculation utilities\n│   │   └── rate-limiter.ts      # Budget protection\n│   ├── layout.tsx\n│   └── page.tsx\n├── vercel.json                   # Vercel configuration\n└── package.json\n```",
    "promptTokens": 178,
    "completionTokens": 465,
    "cost": 0.001733
  }
}